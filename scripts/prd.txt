프로젝트: 거짓 리뷰 분석 크롤러

개요:
본 프로젝트는 거짓 리뷰 탐지를 위한 ML 모델 학습에 필요한 데이터를 수집하기 위한 크롤러를 개발하는 것을 목표로 합니다. 주요 한국 이커머스 플랫폼(쿠팡과 네이버)의 리뷰 데이터를 수집하여 구조화된 형식으로 저장합니다.

주요 요구사항:

1. 자동 사이트 분류
- 쿠팡 또는 네이버 상품 URL 입력 수용
- URL로부터 자동으로 서비스 타입 식별
- 잘못된 URL 처리

2. 리뷰 데이터 수집
- 각 리뷰에서 다음 데이터 포인트 추출:
  * 상품명
  * 작성자 (마스킹 될 수 있음)
  * 작성일
  * 별점 (1-5점)
  * 리뷰 내용
  * 상품 ID (URL에서 추출)
- CSV 형식으로 데이터 저장 (파일명 형식: YYYYMMDD_서비스이름_상품코드.csv)

3. 크롤링 방지 기능 우회
- User-Agent 위조를 통한 일반 브라우저 동작 모방
- 속도 제한 및 차단 메커니즘 처리
- 요청 간 적절한 딜레이 구현

4. 자동 페이지 탐색
- 리뷰 페이지네이션 감지 및 탐색
- 최대 페이지 수 설정 가능
- 실제 페이지 수가 요청된 수보다 적은 경우 처리

사용자 인터페이스:
- 커맨드 라인 인터페이스로 두 가지 입력 요구:
  1. 상품 URL 입력
  2. 크롤링할 최대 리뷰 페이지 수

기술 요구사항:

1. Python 구현
- Python을 사용한 크롤러 구현
- 다른 사이트 핸들러를 위한 모듈식 설계
- 적절한 HTTP 클라이언트 라이브러리 사용 (requests/aiohttp)
- CSV 처리를 위한 라이브러리 사용

2. 오류 처리
- 입력 URL 유효성 검사
- 네트워크 오류 적절한 처리
- 다양한 페이지 구조에 대한 파싱 오류 처리
- 의미 있는 오류 메시지 제공

3. 데이터 처리
- 수집된 데이터 정제 및 정규화
- 다양한 날짜 형식 처리
- 일관된 CSV 인코딩 보장
- 저장 전 데이터 유효성 검증

4. 성능
- 적절한 요청 딜레이 구현
- 대량 리뷰 세트에 대한 효율적인 메모리 관리
- 파싱 작업 최적화

프로젝트 제약사항:
- robots.txt 가이드라인 준수
- 사이트별 속도 제한 처리
- 쿠팡과 네이버 쇼핑 모두 지원
- 표준 Python 환경에서 실행 가능

성공 기준:
1. 지원되는 두 플랫폼에서 리뷰 크롤링 성공
2. 올바른 형식의 CSV 파일 생성
3. 페이지네이션 정확한 처리
4. 기본적인 크롤러 방지 기능 우회
5. 충돌 없는 안정적인 작동

향후 고려사항:
- 추가 이커머스 플랫폼 지원
- ML 모델 학습 파이프라인과의 통합
- 자동화된 데이터 수집을 위한 API 인터페이스
- 분산 크롤링 지원 